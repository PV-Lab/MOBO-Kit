{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84796167",
   "metadata": {},
   "source": [
    "# MOBO Workshop Demo\n",
    "\n",
    "Welcome! This demo shows a complete **Multi-Objective Bayesian Optimization (MOBO)** workflow that only\n",
    "requires you to provide a single **CSV** with your inputs and objectives, then set a **save path** where\n",
    "outputs are written.\n",
    "\n",
    "**You will edit just two things:**\n",
    "1. `csv_path` → point to your data file\n",
    "2. `save_path` → directory for results and plots\n",
    "\n",
    "## Outline\n",
    "- [0. Setup & Imports](#0-Setup--Imports)\n",
    "- [1. Load Your Data](#1-Load-Your-Data)  \n",
    "  - [Existing data present](#Existing-data-present)  \n",
    "  - [Starting from scratch / LHS](#Starting-from-scratch--LHS)\n",
    "- [2. Normalize & Convert to Tensors](#Inputs-%E2%86%92-01)\n",
    "- [3. Fit Gaussian Process (GP) Models](#3-Fit-Gaussian-Process-GP-Models)\n",
    "- [4. LOOCV Model Selection (optional)](#4-loocv_select_models-optional)\n",
    "- [5. Posterior Predictions and Diagnostics](#5-Posterior-Predictions-and-Diagnostics)\n",
    "- [6. Acquisition & Proposing New Batches](#6-Acquisition)\n",
    "- [7. Candidate Analysis & Visualization](#X_next--Candidate-Analysis)\n",
    "- [8. Visualize Progress (Hypervolume & Pareto)](#8-Visualize-Progress)\n",
    "- [9. Save Results](#9-save-outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b92d9",
   "metadata": {},
   "source": [
    "## 0. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9601d",
   "metadata": {},
   "source": [
    "**Imports** Bring in libraries for data handling, modeling, and plotting.  \n",
    "If CUDA isn't available, the CPU path still works for a workshop-scale demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eaaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & setup ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Core\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Torch / BoTorch / GPyTorch\n",
    "import torch\n",
    "from src.utils import csv_to_config, split_XY, get_objective_names, np_to_torch\n",
    "from src.design import build_design_from_config\n",
    "\n",
    "from src.lhs import lhs_dataframe, lhs_dataframe_optimized\n",
    "from src.constraints import constraints_from_config\n",
    "\n",
    "from src.plotting import plot_distribution, plot_correlation_heatmap, plot_PCA\n",
    "\n",
    "from src.data import x_normalizer_np\n",
    "\n",
    "from src.models import fit_gp_models\n",
    "from src.constraints import check_clausius_clapeyron_np\n",
    "from src.lhs import lhs_dataframe\n",
    "#from src.plotting import plot_pareto, plot_hypervolume_trajectory\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18716c1e",
   "metadata": {},
   "source": [
    "## Point to CSV and save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c88e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CSV (change for your data)\n",
    "csv_path = \"../data/processed/configCSV_example.csv\"\n",
    "save_path = \"../results/demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a087c",
   "metadata": {},
   "source": [
    "## 1. Load Your Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41089d",
   "metadata": {},
   "source": [
    "## Step 1 — Load CSV → Build Config & Design (two use cases)\n",
    "\n",
    "This notebook supports **two starting points**:\n",
    "\n",
    "1) [Existing data present](#Existing-data-present)   \n",
    "   - CSV has header rows (units/start/stop/step), then data rows.\n",
    "   - We’ll build a `config`, create a `design`, then split into inputs `X` and objectives `Y`.\n",
    "\n",
    "2) [Starting from scratch](#starting-from-scratch-no-data-yet)\n",
    "   - CSV has header rows only (units/start/stop/step), no data rows.\n",
    "   - We’ll still build `config` and `design`, but skip data split and instead **generate an initial LHS** for you to run in the lab.\n",
    "\n",
    "> Tip: The expected CSV layout:\n",
    "> - Row 1: **variable_names**  \n",
    "> - Row 2: **units**  \n",
    "> - Row 3: **start** values  \n",
    "> - Row 4: **stop** values  \n",
    "> - Row 5: **step** values \n",
    "> - Row 6: **empty** \n",
    "> - Row 6+: experimental data (if you have any)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b2ca0",
   "metadata": {},
   "source": [
    "<a id=\"existing-data-present\"></a>\n",
    "\n",
    "### Existing data present\n",
    "\n",
    "If your CSV already has experimental results (rows 6 and below):\n",
    "\n",
    "We will:\n",
    "1. Convert the CSV into a config dictionary.  \n",
    "2. Build a `Design` object that stores variable ranges and grids.  \n",
    "3. Split into `X` (inputs) and `Y` (objectives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert CSV to config dict + YAML\n",
    "config = csv_to_config(csv_path, output_path=os.path.join(\"../configs\", \"demo_config.yaml\"))\n",
    "\n",
    "# 2. Build design space from config\n",
    "design = build_design_from_config(config)\n",
    "\n",
    "# 3. Load CSV fully, then split into X, Y\n",
    "df = pd.read_csv(csv_path)\n",
    "X_df, Y_df = split_XY(df, design, config)\n",
    "\n",
    "print(\"Design inputs:\", design.names)\n",
    "print(\"Lower bounds:\", design.lowers)\n",
    "print(\"Upper bounds:\", design.uppers)\n",
    "print(\"Steps:\", design.steps)\n",
    "print(\"Objectives:\", config[\"objectives\"][\"names\"])\n",
    "print(\"X shape:\", X_df.shape, \"Y shape:\", Y_df.shape)\n",
    "\n",
    "display(pd.DataFrame(X_df, columns=design.names).head())\n",
    "obj_names = get_objective_names(config)\n",
    "display(pd.DataFrame(Y_df, columns=obj_names).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e719d6af",
   "metadata": {},
   "source": [
    "### Starting from scratch / LHS\n",
    "\n",
    "If your CSV only has the **metadata rows** (variable names, units, start, stop, step) but **no data rows**,  \n",
    "we generate an **initial batch** of experiments using **Latin Hypercube Sampling (LHS)**.  \n",
    "This ensures your first experiments cover the parameter space evenly.\n",
    "\n",
    "We will:\n",
    "1. Convert the CSV into a config dictionary.  \n",
    "2. Build a `Design` object that stores variable ranges and grids.  \n",
    "3. Add constraints (if necessary)\n",
    "4. Generate an LHS dataframe of a given batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94998c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert CSV to config dict + YAML\n",
    "config = csv_to_config(csv_path, output_path=os.path.join(\"../configs\", \"auto_config.yaml\"))\n",
    "\n",
    "# 2. Build design space from config\n",
    "design = build_design_from_config(config)\n",
    "df = pd.read_csv(csv_path)\n",
    "obj_names = get_objective_names(config)\n",
    "\n",
    "#3. Add constraints (if necessary)\n",
    "row_constraints = constraints_from_config(config, design)\n",
    "max_abs_corr = 0.2\n",
    "\n",
    "#4. Generate an LHS dataframe of a given batch size.\n",
    "lhs_batch_size = 20\n",
    "lhs_df = lhs_dataframe_optimized(design, n=lhs_batch_size, seed=42, row_constraints=row_constraints, max_abs_corr=max_abs_corr, verbose=True)\n",
    "display(lhs_df.head())\n",
    "print(f\"Objective names: {obj_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c0ed2",
   "metadata": {},
   "source": [
    "### Visualize data distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_distribution(lhs_df, title=\"LHS Feature Distributions\", save=os.path.join(save_path, \"lhs_dist.png\"))\n",
    "_ = plot_correlation_heatmap(lhs_df, title=\"LHS Pearson Correlation\", save=os.path.join(save_path, \"lhs_corr.png\"))\n",
    "_ = plot_PCA(lhs_df, title=\"LHS PCA (2D)\", save=os.path.join(save_path, \"lhs_pca.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5fa6f",
   "metadata": {},
   "source": [
    "## 2. Normalize Data and Create Tensors/Arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf47096",
   "metadata": {},
   "source": [
    "**Inputs.** Scale to [0, 1] per dimension. \n",
    "\n",
    "This helps GP hyperparameters learn sensibly. There are utility functions to normalize and standardize the outputs, but this is currently handled internally in `fit_gp_models`.\n",
    "\n",
    "**Tensors.** Some Botorch functions use tensor objects rather than arrays and vice versa. It's good to have both!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs → [0,1]\n",
    "X_np = X_df.to_numpy()  ## OR lhs_df\n",
    "X_norm = x_normalizer_np(X_np, design)\n",
    "\n",
    "# Tensors\n",
    "Y_np = Y_df.to_numpy()\n",
    "(X_t, Y_t), _ = np_to_torch(X_norm, Y_np, device=device, return_device=True)\n",
    "\n",
    "print(\"X_scaled shape:\", X_t.shape, \"Y_scaled shape:\", Y_t.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a6060",
   "metadata": {},
   "source": [
    "## 3. Fit Gaussian Process (GP) Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef36573",
   "metadata": {},
   "source": [
    "We now fit one **Gaussian Process (GP)** per objective (e.g. PCE, Stability, Repeatability).  \n",
    "This gives us a flexible, uncertainty-aware model of how the objectives vary with process parameters.\n",
    "\n",
    "- **Defaults:**  \n",
    "  - Kernel: `MaternKernel(nu=2.5, ard_num_dims=d)` (smooth, ARD per feature)  \n",
    "  - Likelihood: `GaussianLikelihood` with an inferred homoskedastic noise level  \n",
    "    (includes a small positive floor to prevent overfitting)\n",
    "\n",
    "- **Optional overrides:**  \n",
    "  - You may pass your own **kernel function(s)** (e.g., RBF, Matern with different ν, etc.)  \n",
    "  - You may pass **noise priors** (e.g., LogNormal or Gamma) to guide the noise estimate.\n",
    "\n",
    "This example shows passing custom priors and a kernel to demonstrate how it works, but you can omit them entirely to use the defaults.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.priors import LogNormalPrior, GammaPrior\n",
    "from gpytorch.kernels import MaternKernel, RBFKernel, PeriodicKernel, ConstantKernel\n",
    "\n",
    "noise_priors = [\n",
    "    LogNormalPrior(-3.0, 0.5),\n",
    "    LogNormalPrior(-2.0, 0.5),\n",
    "    LogNormalPrior(-4.0, 0.5),\n",
    "]\n",
    "\n",
    "kernel_fn = lambda d: MaternKernel(nu=2.5, ard_num_dims=d)\n",
    "\n",
    "model = fit_gp_models(X_t, Y_t, noise_priors=noise_priors, kernel_fn=kernel_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f931a",
   "metadata": {},
   "source": [
    "## 4. LOOCV Model Selection (optional)\n",
    "\n",
    "Instead of hand-choosing kernel functions and noise priors, you can let the repo \n",
    "**automatically compare candidates** using **Leave-One-Out Cross-Validation (LOOCV)**.\n",
    "\n",
    "- The function `loocv_select_models` tries multiple `(kernel × noise)` combinations.\n",
    "- By default, it uses:\n",
    "  - **Kernel options:** RBF, Matern(ν=0.5), Matern(ν=1.5), Matern(ν=2.5)  \n",
    "  - **Noise priors:** `None` (free noise level) and `LogNormal(-4.0, 0.5)`\n",
    "- For each fold (leave one point out), it re-fits the GP, predicts the held-out point, \n",
    "  and records **R²** and **RMSE**.  \n",
    "- After sweeping all combinations, it selects the best configuration per objective \n",
    "  and re-fits on the full dataset.\n",
    "\n",
    "**Pros:** \n",
    "- removes guesswork.\n",
    "- gives metrics for each option.  \n",
    "\n",
    "**Cons:** \n",
    "- expensive when you have many data points (since it re-fits N×(#kernels×#priors) times).\n",
    "- poor fits when handling very small and noisy datasets and have convergence errors.\n",
    "\n",
    "You can skip this step if you are happy with the defaults from Step 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88052f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import loocv_select_models, default_noise_options, default_kernel_options\n",
    "\n",
    "noise_options = default_noise_options()\n",
    "kernel_options = default_kernel_options()\n",
    "\n",
    "# Run LOOCV across default kernels & priors\n",
    "best_model, results_df = loocv_select_models(\n",
    "    train_X=X_t,\n",
    "    train_Y=Y_t,\n",
    "    objective_names=obj_names,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "model_cv = best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73d832",
   "metadata": {},
   "source": [
    "### Display LOOCV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)\n",
    "for i, gp in enumerate(model_cv.models):\n",
    "    print(f\"--- Model {i+1} ({obj_names[i]}) ---\")\n",
    "    # Kernel type\n",
    "    kernel = gp.covar_module.base_kernel\n",
    "    print(\"Kernel:\", type(kernel).__name__)\n",
    "\n",
    "    # Check Matern ν if it's a Matern kernel\n",
    "    if hasattr(kernel, \"nu\"):\n",
    "        print(\"Matern ν:\", kernel.nu)\n",
    "\n",
    "    # Noise prior info\n",
    "    if hasattr(gp.likelihood.noise_covar, \"noise_prior\"):\n",
    "        prior_type = type(gp.likelihood.noise_covar.noise_prior).__name__\n",
    "    else:\n",
    "        prior_type = \"None\"\n",
    "    print(\"Noise prior:\", prior_type)\n",
    "    \n",
    "    print(\"Lengthscales:\", gp.covar_module.base_kernel.lengthscale.detach().cpu().numpy().flatten())\n",
    "    print(\"Outputscale:\", gp.covar_module.outputscale.item())\n",
    "    print(\"Noise:\", gp.likelihood.noise.item())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91798dcb",
   "metadata": {},
   "source": [
    "## 5. Posterior Predictions & Diagnostics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa215f",
   "metadata": {},
   "source": [
    "With a fitted GP model (`model` from Step 3 or 4), we can now evaluate how well it explains the data.  \n",
    "This step does two things:\n",
    "\n",
    "1. **Posterior predictions:**  \n",
    "   - Use `posterior_report(model, X_t)` to get the **predicted mean** and **uncertainty (std)** for each objective at the training points.  \n",
    "   - These predictions are automatically converted back into the original units (because the model internally standardizes outputs).\n",
    "\n",
    "2. **Diagnostics:**  \n",
    "   - `plot_parity_np` shows **predicted vs. true values** for each objective, with optional error bars from the GP’s predictive uncertainty.  \n",
    "   - `plot_shap` estimates **feature importance** (mean absolute SHAP values per input dimension), so you can see which process parameters most influence each objective.  \n",
    "   - `compute_metrics` calculates **R²** and **RMSE**, and can also return per-point residuals and z-scores to help check model fit quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import posterior_report\n",
    "from src.plotting import plot_parity_np, plot_shap\n",
    "from src.metrics import compute_metrics\n",
    "\n",
    "pred_mean, pred_std = posterior_report(model, X_t)\n",
    "fig_train, metrics_train = plot_parity_np(Y_np, pred_mean, pred_std, objective_names=obj_names, save=os.path.join(save_path, \"parity_train.png\"))\n",
    "fig_shap = plot_shap(design, X_np, model, objective_names=obj_names, save=os.path.join(save_path, \"shap.png\"))\n",
    "\n",
    "metrics_df = compute_metrics(\n",
    "    true_Y=Y_np,               # numpy array of your observed objectives\n",
    "    pred_mean=pred_mean,\n",
    "    pred_std=pred_std,\n",
    "    objective_names=obj_names,\n",
    "    add_residuals=True,       # set True to include per-point residual vectors\n",
    "    add_zscores=True,         # set True to include per-point z-score vectors\n",
    ")\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd9ea3",
   "metadata": {},
   "source": [
    "## 6. Acquisition: Pareto Front & Proposing New Experiments\n",
    "\n",
    "With our GP model trained, we now use an **acquisition function** to decide *where to sample next*.  \n",
    "In multi-objective BO, we look for candidates that **expand the Pareto front** and improve **hypervolume**.\n",
    "\n",
    "### Pareto Front & Hypervolume\n",
    "- The **Pareto front** consists of non-dominated points: no other point is strictly better across *all* objectives.  \n",
    "- The **hypervolume** measures the space dominated by the Pareto front relative to a chosen **reference point**.  \n",
    "- As we add better candidates, the hypervolume increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ea0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import compute_ref_pareto_hv\n",
    "\n",
    "_, pareto_Y_t, hv_val = compute_ref_pareto_hv(Y_t)\n",
    "ref_point_t = torch.tensor([-0.01, -0.01, -0.01], dtype=X_t.dtype, device=X_t.device)\n",
    "print(\"Hypervolume:\", hv_val, \"| Pareto count:\", pareto_Y_t.shape[0])\n",
    "print(pareto_Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6f156",
   "metadata": {},
   "source": [
    "### Proposing New Candidates\n",
    "\n",
    "We then call `propose_batch`, which:\n",
    "1. Builds a **qLogNoisyExpectedHypervolumeImprovement** acquisition function (default).\n",
    "2. Optimizes it over the normalized design space.\n",
    "3. Converts back to **physical units**, snapping to valid grids.\n",
    "4. Enforces row constraints (e.g. Clausius–Clapeyron).\n",
    "5. Returns a batch of promising candidates.\n",
    "\n",
    "You can also add **outcome constraints** (e.g. enforce PCE ≥ 15%).\n",
    "\n",
    "### Balancing Exploration vs. Exploitation\n",
    "\n",
    "The following parameters influence the tradeoff:\n",
    "- num_restarts and raw_samples: higher values → more global search (exploration).\n",
    "- sample_shape (MC samples): larger → more accurate acquisition evaluation, but slower.\n",
    "- sequential:\n",
    "    - True → proposes candidates one-by-one, each conditioned on the last (more exploitative).\n",
    "    - False → proposes all in parallel (more exploratory, but less coordinated).\n",
    "- Outcome constraints can bias selection toward “safe” regions, shifting away from exploration.\n",
    "\n",
    "In practice:\n",
    "- For early rounds, set larger raw_samples (e.g. 1024) and keep sequential=False to encourage exploration.\n",
    "- For later rounds, reduce these and turn sequential=True to refine promising regions (exploitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d929ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.acquisition import propose_batch, outcome_ge, outcome_le\n",
    "\n",
    "row_constraints = constraints_from_config(config, design)\n",
    "pce_threshold = 15.0  # Example: 15% PCE minimum\n",
    "repeatability_threshold = 8  # Example: 0.1 maximum repeatability\n",
    "\n",
    "outcome_constraints = [\n",
    "        outcome_ge(obj_idx=0, thresh=pce_threshold),  # PCE >= 15%\n",
    "        outcome_le(obj_idx=2, thresh=repeatability_threshold),  # Repeatability <= 0.1\n",
    "    ]\n",
    "\n",
    "out = propose_batch(design, model, X_t, ref_point_t, batch_size=5, row_constraints=row_constraints, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dfb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c5fd8",
   "metadata": {},
   "source": [
    "## 7. Review Proposed Batch & Predicted Outcomes\n",
    "\n",
    "Now that we’ve generated candidates, let’s:\n",
    "1) **Inspect the proposed settings** in original (physical) units.  \n",
    "2) **Interpret acquisition values** (log nEHVI → EHVI).  \n",
    "3) **Preview model predictions** (mean ± uncertainty) for each objective at the proposed points.\n",
    "\n",
    "### 1) Inspect the proposed candidates\n",
    "- `out[\"X_phys\"]` is already **de-normalized and snapped** to any discrete grids defined in the `Design`.\n",
    "- We display it as a tidy dataframe with the original column names.\n",
    "\n",
    "### 2) Acquisition values (how “good” each candidate is)\n",
    "- With `use_lognehvi=True` (default), `out[\"acq_val\"]` contains **log(EHVI)** for numerical stability.  \n",
    "- Exponentiate to get **EHVI** (expected hypervolume improvement).  \n",
    "- Larger EHVI ⇒ greater expected contribution to the Pareto front.\n",
    "\n",
    "### 3) Predicted outcomes for the proposed batch\n",
    "- We pass the **normalized** candidates (`out[\"X_norm\"]`) through the fitted model.  \n",
    "- The bar plot shows **mean** predictions with **uncertainty bars** (predictive std) for each objective.\n",
    "\n",
    "> Notes\n",
    "> - Objectives are assumed to be **maximized** here. If you minimize any objective, flip the sign upstream for consistency.\n",
    "> - Before running the batch in the lab, you can optionally **save** the table to CSV (e.g., `X_next.to_csv(...)`) to hand off to execution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cb13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting import plot_bar\n",
    "\n",
    "# 1. Display proposed candidates\n",
    "X_next = out[\"X_phys\"]\n",
    "X_next_df = pd.DataFrame(out[\"X_phys\"], columns=design.names)\n",
    "display(X_next)\n",
    "\n",
    "# 2. Acquisition value analysis\n",
    "print(f\"Acquisition Value Analysis:\")\n",
    "print(f\"   Raw acquisition values (log(nEHVI)): {[f'{v:.6f}' for v in out['acq_val']]}\")\n",
    "# Convert from log(EHVI) to EHVI since use_lognehvi=True (default)\n",
    "ehvi_values = [np.exp(v) for v in out['acq_val']]\n",
    "print(f\"   Actual EHVI values: {[f'{v:.6f}' for v in ehvi_values]}\")\n",
    "\n",
    "# 3. Predicted outcomes for the proposed batch\n",
    "X_norm = out[\"X_norm\"]\n",
    "X_norm_t = np_to_torch(X_norm, device=X_t.device)\n",
    "pred_mean_new, pred_std_new = posterior_report(model, X_norm_t)\n",
    "\n",
    "fig_bar = plot_bar(pred_mean_new, pred_std_new, labels=obj_names, save=os.path.join(save_path, \"proposed_bar.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6014a48",
   "metadata": {},
   "source": [
    "## 8. Visualize Your Progress (Work in Progress...)\n",
    "\n",
    "We track learning progress by plotting the **hypervolume (HV)** after each batch of **observed** results.  \n",
    "As you collect new data and the Pareto front improves, HV should **monotonically increase** (or stay flat).\n",
    "\n",
    "**Key points**\n",
    "- Use **observed outcomes** (not predictions).  \n",
    "- Keep a **fixed reference point** `ref_point_t` across all batches (choose it once at the start, slightly worse than the worst feasible values for each objective, in original units).  \n",
    "- Compute HV on the **cumulative dataset** up through each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1980a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Reference point (original units) — pick once and keep fixed across batches\n",
    "ref_point_np = np.array([-0.01, -0.01, -0.01])\n",
    "\n",
    "# 2) HV on current observed data\n",
    "_, pareto_Y_t, hv_val = compute_ref_pareto_hv(Y_t, ref_point_np)\n",
    "print(f\"Current HV (observed data): {hv_val:.6f} | Pareto count: {pareto_Y_t.shape[0]}\")\n",
    "\n",
    "# 3) Append predicted means for proposed batch (demo only)\n",
    "Y_next_t = np_to_torch(pred_mean_new, device=Y_t.device)\n",
    "combined_Y = torch.cat([Y_t, Y_next_t], dim=0)\n",
    "\n",
    "_, pareto_Y_combined, hv_val_combined = compute_ref_pareto_hv(combined_Y, ref_point_np)\n",
    "print(f\"Demo HV with predictions: {hv_val_combined:.6f} | Pareto count: {pareto_Y_combined.shape[0]}\")\n",
    "\n",
    "# 4) Simple before/after plot\n",
    "hv_vals = [hv_val, hv_val_combined]\n",
    "labels = [\"Observed so far\", \"Observed + predicted next batch\"]\n",
    "\n",
    "plt.figure(figsize=(5.5, 4))\n",
    "plt.bar(range(len(hv_vals)), hv_vals)\n",
    "plt.xticks(range(len(hv_vals)), labels, rotation=10)\n",
    "plt.ylabel(\"Hypervolume\")\n",
    "plt.title(\"Hypervolume (demo with predicted outcomes)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_path, \"hv_demo_with_predictions.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230729a",
   "metadata": {},
   "source": [
    "This plot shows the **current Pareto front** (green) in 3D objective space and an optional **predicted next batch**.  \n",
    "\n",
    "The **reference point** is drawn as a red star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Settings: mark which objectives are maximized ---\n",
    "# Example: [PCE (max), Stability (max), Repeatability (min)]\n",
    "maximize = [True, True, True]\n",
    "\n",
    "def _flip_for_plot(Y_t, maximize_flags):\n",
    "    \"\"\"\n",
    "    Convert a (K, M) tensor Y_t to numpy and flip any minimized objectives\n",
    "    so that all axes read 'higher is better' in the plot.\n",
    "    \"\"\"\n",
    "    Y_np = Y_t.detach().cpu().numpy().copy()\n",
    "    for j, is_max in enumerate(maximize_flags):\n",
    "        if not is_max:\n",
    "            Y_np[:, j] = -Y_np[:, j]\n",
    "    return Y_np\n",
    "\n",
    "# Prepare arrays (Pareto + reference point, both already in ORIGINAL units)\n",
    "pareto_Y_np_plot = _flip_for_plot(pareto_Y_t, maximize)\n",
    "ref_point_np_plot = _flip_for_plot(ref_point_t.view(1, -1), maximize)\n",
    "\n",
    "# Optional: include predicted outcomes for the newly proposed batch\n",
    "# (Uncomment if you have Y_next_t from earlier demo code)\n",
    "has_next = 'Y_next_t' in globals()\n",
    "if has_next and Y_next_t is not None:\n",
    "    next_Y_np_plot = _flip_for_plot(Y_next_t, maximize)\n",
    "\n",
    "# --- 3D scatter ---\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Pareto points (observed)\n",
    "ax.scatter(\n",
    "    pareto_Y_np_plot[:, 0], pareto_Y_np_plot[:, 1], pareto_Y_np_plot[:, 2],\n",
    "    c='green', s=50, label='Pareto (observed)', depthshade=True\n",
    ")\n",
    "\n",
    "# Optional: predicted next batch\n",
    "if has_next and Y_next_t is not None:\n",
    "    ax.scatter(\n",
    "        next_Y_np_plot[:, 0], next_Y_np_plot[:, 1], next_Y_np_plot[:, 2],\n",
    "        c='orange', s=60, marker='^', label='Proposed (predicted)', depthshade=True\n",
    "    )\n",
    "\n",
    "# Reference point\n",
    "ax.scatter(\n",
    "    ref_point_np_plot[0, 0], ref_point_np_plot[0, 1], ref_point_np_plot[0, 2],\n",
    "    c='red', s=80, marker='*', label='Reference point'\n",
    ")\n",
    "\n",
    "# Axis labels (update names to your objectives if needed)\n",
    "ax.set_xlabel('PCE (higher is better)', fontsize=11)\n",
    "ax.set_ylabel('Stability (higher is better)', fontsize=11)\n",
    "ax.set_zlabel('Repeatability (flipped if minimized)', fontsize=11)\n",
    "\n",
    "ax.set_title('Pareto Front (3D)', fontsize=13)\n",
    "ax.legend(loc='best')\n",
    "ax.view_init(elev=25, azim=-45)\n",
    "plt.tight_layout()\n",
    "# Optionally save:\n",
    "# plt.savefig(os.path.join(save_path, \"pareto_3d.png\"), dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07896ef",
   "metadata": {},
   "source": [
    "## 9. Save Outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e533308",
   "metadata": {},
   "source": [
    "Get it right back into that same file format you so tirelessly created!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_next_df = pd.DataFrame(pred_mean_new, columns=obj_names)\n",
    "df_new = pd.concat([X_next_df, Y_next_df], axis=1)\n",
    "\n",
    "df_batch_1 = pd.concat([df, df_new], axis=0)\n",
    "df_batch_1.to_csv(os.path.join(save_path, \"batch_1.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
