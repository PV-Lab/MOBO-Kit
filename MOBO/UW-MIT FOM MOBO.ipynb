{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda845d3-bb40-428a-b2a5-e4cce3c5a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "\n",
    "from scipy.spatial import Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "from botorch.utils.multi_objective.box_decompositions import NondominatedPartitioning\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "\n",
    "from botorch.utils.transforms import unnormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e062d-8959-4682-bf9b-8f05a47f83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_normalizer(X, var_array):\n",
    "    \n",
    "    def max_min_scaler(x, x_max, x_min):\n",
    "        return (x-x_min)/(x_max-x_min)\n",
    "    x_norm = []\n",
    "    for x in (X):\n",
    "           x_norm.append([max_min_scaler(x[i], \n",
    "                                         max(var_array[i]), \n",
    "                                         min(var_array[i])) for i in range(len(x))])\n",
    "            \n",
    "    return x_norm\n",
    "\n",
    "def x_denormalizer(x_norm, var_array):\n",
    "    \n",
    "    def max_min_rescaler(x, x_max, x_min):\n",
    "        return x*(x_max-x_min)+x_min\n",
    "    x_original = []\n",
    "    for x in (x_norm):\n",
    "           x_original.append([max_min_rescaler(x[i], \n",
    "                                         max(var_array[i]), \n",
    "                                         min(var_array[i])) for i in range(len(x))])\n",
    "            \n",
    "    return x_original\n",
    "\n",
    "def get_closest_value(given_value, array_list):\n",
    "    absolute_difference_function = lambda list_value : abs(list_value - given_value)\n",
    "    closest_value = min(array_list, key=absolute_difference_function)\n",
    "    return closest_value\n",
    "    \n",
    "def get_closest_array(suggested_x, var_list):\n",
    "    modified_array = []\n",
    "    for x in suggested_x:\n",
    "        modified_array.append([get_closest_value(x[i], var_list[i]) for i in range(len(x))])\n",
    "    return np.array(modified_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcba47-fe51-47be-9be4-798dc3aa4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_linspace(start, stop, step):\n",
    "    num_points = int(round((stop - start) / step)) + 1\n",
    "    return np.round(np.linspace(start, stop, num_points), 4)  # round for cleaner floats\n",
    "\n",
    "speed_inorg_var   = make_linspace(0.25, 0.55, 0.01)  # m/min\n",
    "speed_org_var     = make_linspace(0.25, 0.55, 0.01)  # m/min\n",
    "inkFL_inorg_var   = make_linspace(80, 200, 1)       # uL/min\n",
    "inkFL_org_var     = make_linspace(100, 280, 1)      # uL/min\n",
    "conc_inorg_var    = make_linspace(0.8, 1.6, 0.05)     # M\n",
    "conc_org_var      = make_linspace(0.4, 1.2, 0.05)     # M\n",
    "humidity_var      = make_linspace(11, 44, 1)        # %RH\n",
    "temp_var          = make_linspace(20, 65, 5)        # Â°C\n",
    "\n",
    "# Tracking unique values\n",
    "speed_inorg_num   = len(speed_inorg_var)\n",
    "speed_org_num     = len(speed_org_var)\n",
    "inkFL_inorg_num   = len(inkFL_inorg_var)\n",
    "inkFL_org_num     = len(inkFL_org_var)\n",
    "conc_inorg_num    = len(conc_inorg_var)\n",
    "conc_org_num      = len(conc_org_var)\n",
    "humidity_num      = len(humidity_var)\n",
    "temp_num          = len(temp_var)\n",
    "\n",
    "# Pack into var_array for downstream normalization\n",
    "var_array = [speed_inorg_var, speed_org_var, \n",
    "             inkFL_inorg_var, inkFL_org_var,\n",
    "             conc_inorg_var, conc_org_var,\n",
    "             humidity_var, temp_var]\n",
    "\n",
    "x_labels = ['Speed (Inorg) [m/min]', 'Speed (Org) [m/min]', \n",
    "            'inkFL (Inorg) [uL/min]', 'inkFL (Org) [uL/min]',\n",
    "            'Conc. (Inorg) [M]', 'Conc. (Org) [M]',\n",
    "            'RH [%]', 'Temp [C]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85426d-2ead-4f86-b604-bb9bc2c6c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_space = ParameterSpace([ContinuousParameter('x1', 0, 1),\n",
    "#                                   ContinuousParameter('x2', 0, 1),\n",
    "#                                   ContinuousParameter('x3', 0, 1),\n",
    "#                                   ContinuousParameter('x4', 0, 1),\n",
    "#                                   ContinuousParameter('x5', 0, 1),\n",
    "#                                   ContinuousParameter('x6', 0, 1),\n",
    "#                                   ContinuousParameter('x7', 0, 1),\n",
    "#                                   ContinuousParameter('x8', 0, 1),\n",
    "#                                  ])\n",
    "\n",
    "## why is the parameter space different in the round 1 of the Joule code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948d7fa-4a19-4ead-b20d-988188fc711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clausius_clapeyron(humidity_vals, temp_vals):\n",
    "    \"\"\"\n",
    "    Return boolean mask for valid points satisfying Clausius-Clapeyron constraints.\n",
    "    Simplified: Ensures RH and Temp do not imply >100% saturation.\n",
    "    \"\"\"\n",
    "    # Saturation vapor pressure approximation (T in Celsius)\n",
    "    # Tetens formula: es(T) = 0.6108 * exp((17.27*T)/(T + 237.3)) [kPa]\n",
    "    # RH = (actual / saturation) * 100\n",
    "    # Check that vapor pressure does not exceed saturation vapor pressure\n",
    "    valid_mask = []\n",
    "    for RH, T in zip(humidity_vals, temp_vals):\n",
    "        es = 0.6108 * np.exp((17.27 * T) / (T + 237.3))\n",
    "        e = RH / 100.0 * es  # approximate check\n",
    "        valid_mask.append(e <= es)\n",
    "    return np.array(valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce471e12-4e94-47ad-9588-f2040cf3e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your real LHS experimental results (replace with real path)\n",
    "dataset_final = pd.read_csv('path/to/your/real_lhs_results.csv')\n",
    "\n",
    "#Extract input features (first 8 columns assumed to be process parameters) ===\n",
    "X = dataset_final.iloc[:, 0:8].values  # shape: (8, 8)\n",
    "\n",
    "#Extract targets\n",
    "y = dataset_final[['PCE', 'Stability', 'Repeatability']].values  # shape: (8, 3)\n",
    "\n",
    "#Standardize input and output\n",
    "X_scaled = x_normalizer(X, var_array)\n",
    "Y_scaled = StandardScaler().fit_transform(y) ## is this the right way to normalize this? do i need to normalize this?\n",
    "\n",
    "#Convert to torch tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_X = torch.tensor(X_scaled, dtype=torch.float32, device=device)\n",
    "train_Y = torch.tensor(Y_scaled, dtype=torch.float32, device=device)\n",
    "\n",
    "#Set seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a759a367-73e3-44e7-a3c3-2094936047f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute pareto front\n",
    "ref_pt = np.array([min(dataset_LHS['Jsc'].values), min(dataset_LHS['Voc'].values), min(dataset_LHS['FF'].values)])\n",
    "# hv = Hypervolume(ref_point=ref_pt)\n",
    "\n",
    "# is_feas = (train_Y <= 0).all(dim=-1)\n",
    "# feas_train_obj = train_Y[is_feas]\n",
    "# if feas_train_obj.shape[0] > 0:\n",
    "#     pareto_mask = is_non_dominated(feas_train_obj)\n",
    "#     pareto_y = feas_train_obj[pareto_mask]\n",
    "#     # compute hypervolume\n",
    "#     volume = hv.compute(pareto_y)\n",
    "# else:\n",
    "#     volume = 0.0\n",
    "\n",
    "# compute pareto front\n",
    "current_pareto_mask = is_non_dominated(train_Y)\n",
    "current_pareto_y = train_Y[current_pareto_mask]\n",
    "current_pareto_ind = []\n",
    "for ind, boo in enumerate(current_pareto_mask.tolist()):\n",
    "    if boo == True:\n",
    "        current_pareto_ind.append(indices_collected[ind]) \n",
    "\n",
    "current_non_pareto_mask = ~current_pareto_mask\n",
    "current_non_pareto_y = np.array(y_train[current_non_pareto_mask])\n",
    "\n",
    "hv = Hypervolume(ref_point= torch.tensor(data = ref_pt))\n",
    "volume = np.round(hv.compute(current_pareto_y), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a1d94-6c7b-4daf-958e-658504edc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied from SIPS code for Pareto visiualization, may need to modify later\n",
    "tri = Delaunay(current_pareto_y)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.scatter3D(np.array(current_pareto_y)[:,0], np.array(current_pareto_y)[:,1], np.array(current_pareto_y)[:,2], c = 'g', s = 10, depthshade = False, label='Pareto optimal')\n",
    "\n",
    "ax.plot_trisurf(np.array(current_pareto_y)[:,0], np.array(current_pareto_y)[:,1], np.array(current_pareto_y)[:,2], triangles = tri.simplices, color ='g', alpha = 0.15, linewidth=0.2, antialiased=False)\n",
    "\n",
    "\n",
    "ax.scatter3D(current_non_pareto_y[:,0], current_non_pareto_y[:,1], current_non_pareto_y[:,2], c = 'b', s = 10, depthshade = False, label='NOT Pareto optimal')\n",
    "ax.scatter3D(np.array(y_pool)[:,0], np.array(y_pool)[:,1], np.array(y_pool)[:,2], c = 'gray', s = 10, alpha = 0.10, depthshade = False, label='NOT discovered')\n",
    "\n",
    "\n",
    "ax.scatter3D(ref_pt[0], ref_pt[1], ref_pt[2], c = 'r', s = 20, depthshade = False, label='Reference Pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel('Jsc', fontsize=16)\n",
    "ax.set_ylabel('Voc', fontsize=16)\n",
    "ax.set_zlabel('FF', fontsize=16)\n",
    "\n",
    "plt.title('Batch ' +str(b)+' | ' + 'Undiscovered:'+str(len(indices_pool)) +' | ' + 'Collected:'+str(len(indices_collected)) +' | ' + 'Pareto front: '+str(percent)+'%' +' | ' + 'HyperVol: '+str(volume), fontsize = 14)\n",
    "\n",
    "plt.legend(numpoints=1, fontsize = 14, loc = 'center left')\n",
    "\n",
    "ax.view_init(25, -61)\n",
    "\n",
    "plt.savefig('SIPS_Batch'+str(b)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921588f7-a878-4948-a9d1-49f1a4a8a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_models = []\n",
    "for i in range(train_Y.shape[1]):\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    gp = SingleTaskGP(train_X, train_Y[:, i:i+1])\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    gp_models.append(gp)\n",
    "\n",
    "# Wrap the models into a multi-output model\n",
    "model = ModelListGP(*gp_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e8457-8c9a-443c-8a87-f854ad53c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_std = torch.cat([gp.posterior(train_X).mean for gp in model.models], dim=-1)  # shape (N, 3)\n",
    "preds = Y_scaler.inverse_transform(preds_std.cpu().numpy())  # shape (N, 3)\n",
    "targets = Y_scaler.inverse_transform(train_Y.cpu().numpy())\n",
    "\n",
    "labels = ['PCE', 'Stability', 'Repeatability']\n",
    "\n",
    "for i in range(3):\n",
    "    y_true = targets[:, i]\n",
    "    y_pred = preds[:, i]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(y_true, y_pred, c='blue', alpha=0.7, s=50)\n",
    "    ax.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'k--', lw=2)\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "    ax.set_xlabel(f'True {labels[i]}', fontsize=14)\n",
    "    ax.set_ylabel(f'Predicted {labels[i]}', fontsize=14)\n",
    "    ax.set_title(f'Parity Plot: {labels[i]}', fontsize=16)\n",
    "    ax.text(0.05, 0.9, f'$R^2$ = {r2:.3f}\\\\nMAE = {mae:.3f}\\\\nRMSE = {rmse:.3f}',\n",
    "            transform=ax.transAxes, fontsize=12, verticalalignment='top')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9b9e3-f525-4d08-90c4-ad369a4151b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct partitioning\n",
    "\n",
    "partitioning = NondominatedPartitioning(ref_point=torch.tensor(ref_pt, device=device), Y=train_Y) #only need this for EHVI, built in to NEHVI\n",
    "# partitioning = NondominatedPartitioning(ref_point=torch.tensor([1.1, 1.1, 1.1], device=device),  # in standardized space\n",
    "#                                         Y=train_Y)\n",
    "\n",
    "# Create acquisition function\n",
    "sampler = SobolQMCNormalSampler(num_samples=128)\n",
    "acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "    model=model,\n",
    "    ref_point=ref_pt,\n",
    "    X_baseline=train_X,\n",
    "    #partitioning=partitioning,\n",
    "    sampler=sampler,\n",
    "    prune_baseline=True,\n",
    "    objective=IdentityMCMultiOutputObjective(outcomes=[0, 1, 2])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b89431-0024-47ad-88af-2ec7bcab4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RESTARTS = 20\n",
    "RAW_SAMPLES = 512\n",
    "\n",
    "MAX_ATTEMPTS = 100\n",
    "valid_candidates = None\n",
    "attempts = 0\n",
    "\n",
    "while attempts < MAX_ATTEMPTS:\n",
    "    attempts += 1\n",
    "\n",
    "    #Optimize acquisition function in normalized space\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=torch.tensor([[0.0] * 8, [1.0] * 8], device=device),\n",
    "        q=5,\n",
    "        num_restarts=20,\n",
    "        raw_samples=512,\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "\n",
    "    #Convert to original space and snap to valid grid\n",
    "    X_cont = x_denormalizer(unnormalize(candidates, bounds).cpu().numpy(), var_array)\n",
    "    X_snapped = get_closest_array(X_cont, var_array)\n",
    "\n",
    "    #Check CC constraint\n",
    "    RH_vals = X_snapped[:, 6]   # RH\n",
    "    Temp_vals = X_snapped[:, 7] # Temp\n",
    "    cc_mask = check_clausius_clapeyron(RH_vals, Temp_vals)\n",
    "\n",
    "    if cc_mask.all():\n",
    "        valid_candidates = X_snapped\n",
    "        print(f\"Found valid candidates after {attempts} attempts.\")\n",
    "        break\n",
    "\n",
    "print(\"Final candidate batch:\" if valid_candidates is not None else \"No valid batch found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14aa1ef-20e1-4e30-85f2-30093ca1b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_norm = torch.tensor(x_normalizer(X_snapped, var_array), dtype=torch.float32, device=device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_new_std = torch.cat([gp.posterior(X_new_norm).mean for gp in model.models], dim=-1)\n",
    "Y_new = Y_scaler.inverse_transform(Y_new_std.cpu().numpy())\n",
    "df_new_batch = pd.DataFrame(X_snapped, columns=x_labels)\n",
    "df_new_batch[['PCE', 'Stability', 'Repeatability']] = Y_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4e078-1e1d-43bb-a8d4-e0e7aa98cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied from old emukit code. this will eventually plot target variable vs process condition...\n",
    "\n",
    "f_obj =  objective_model.model.predict       \n",
    "\n",
    "device_eff = perov_df['PCE']\n",
    "\n",
    "fig = plt.figure(figsize = (9, 9), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "fs = 20\n",
    "exp_cond = np.arange(device_eff.size)\n",
    "#print(exp_cond)\n",
    "exp_eff = np.transpose(device_eff)\n",
    "\n",
    "ax.scatter(exp_cond, exp_eff, #facecolor = 'none',\n",
    "            edgecolor = 'navy', s = 20, alpha = 0.6, label = 'experiment')\n",
    "\n",
    "\n",
    "all_cond = device_eff\n",
    "\n",
    "X_sorted = x_normalizer(perov_df.iloc[:, 0:-1].values)\n",
    "y_pred, y_uncer = f_obj(X_sorted)\n",
    "y_pred = -y_pred[:,-1]\n",
    "y_uncer = np.sqrt(y_uncer[:, -1])\n",
    "\n",
    "ax.scatter(np.arange(len(X_sorted)), y_pred,\n",
    "                s = 50, facecolors='none', alpha = 0.6, edgecolor = 'red', label = 'predicted')\n",
    "ax.errorbar(np.arange(len(X_sorted)), y_pred, yerr = y_uncer,  \n",
    "                 ms = 0, ls = '', capsize = 2, alpha = 0.6, \n",
    "                 color = 'red', zorder = 0)\n",
    "\n",
    "\n",
    "ax.scatter(np.arange(len(X_new))+len(exp_cond), y_pred_new,\n",
    "                s = 50, facecolors='none', alpha = 0.6, edgecolor = 'darkgreen', label = 'suggested')\n",
    "ax.errorbar(np.arange(len(X_new))+len(exp_cond), y_pred_new, yerr = y_uncer_new,  \n",
    "                 ms = 0, ls = '', capsize = 2, alpha = 0.6, \n",
    "                 color = 'darkgreen', zorder = 0)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Current Best Efficiency', fontsize = 20)\n",
    "ax.set_xlabel('Process Condition', fontsize = 20)\n",
    "\n",
    "ax.set_ylim(-1, 25)\n",
    "ax.set_xlim(-1, 48)\n",
    "ax.set_xticks(np.arange(0,41,10))\n",
    "ax.legend(fontsize = fs*0.7)\n",
    "\n",
    "ax.tick_params(direction='in', length=5, width=1, labelsize = fs*.8, grid_alpha = 0.5)\n",
    "ax.grid(True, linestyle='-.')\n",
    "plt.subplots_adjust(wspace = 0.4)\n",
    "plt.legend(fontsize = fs*0.7)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
